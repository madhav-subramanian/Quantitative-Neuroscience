{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39ecae2-e0a0-4a03-9b0f-fd0bb4131964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import matplotlib\n",
    "matplotlib.use('nbagg') # Or 'notebook'\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import scipy\n",
    "import math\n",
    "import scipy.io as sio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import datetime, timedelta, date\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import tifffile\n",
    "\n",
    "from open_ephys.analysis import Session\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import formic as fm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faca51f-3e63-4ba7-bea8-af76eb0ebf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import class after switching to PMI directory\n",
    "os.chdir(os.path.expanduser(\"~/FLEX/\"))\n",
    "from pmi_core import PopulationMuscleImaging as PMI\n",
    "from pmi_core.image.image_series import ImageSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d161747-b297-406f-b084-b5f0b239e6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define event channel names \n",
    "event_channel_names = ['airpuff','airpuff session','UNUSED','camera','speaker 1','speaker 2','audio session','bpod lick trials']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691f5cff-235e-4ca7-8278-ac141ade5e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "which_condition = 'reward'\n",
    "#which_condition = 'startle'\n",
    "#which_condition = 'airpuff'\n",
    "bundle_name = \"experiment1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf521c4-812e-427c-a1ee-b052166fb5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set directory names\n",
    "bundle_dir = '/vol/cortex/cd2/machadolab/Data/madhav/FLEX_trial/M252/05_28_25/'\n",
    "oe_dir = bundle_dir\n",
    "flex_dir = bundle_dir+'M252_Arduino_2025-05-28_kinetix/'\n",
    "bpod_dir = bundle_dir+'M252_Bpod_2025-05-28_kinetix/'\n",
    "\n",
    "# Initialize PMI object\n",
    "pmi = PMI(bundle_dir)\n",
    "# set series number and channels to look for events\n",
    "if which_condition == 'reward':\n",
    "    which_series = 0\n",
    "    event_channels = ['bpod lick trials']\n",
    "elif which_condition == 'airpuff':\n",
    "    which_series = 1\n",
    "    event_channels = ['airpuff']\n",
    "elif which_condition == 'startle':\n",
    "    which_series = 2\n",
    "    event_channels = ['speaker 1','speaker 2']\n",
    "\n",
    "\n",
    "series_name = f'series{which_series:03}'\n",
    "\n",
    "short_name = f\"{bundle_name}, {series_name}\"\n",
    "\n",
    "print(f\"Short name: {short_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8fb98b-a449-4326-aad2-bc7503f2ac93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ephys file\n",
    "\n",
    "\n",
    "# threshold for time between image bursts\n",
    "inter_burst_interval = 0.5\n",
    "\n",
    "which_recording = 2\n",
    "\n",
    "# Load into Session variable\n",
    "session = Session(oe_dir)\n",
    "\n",
    "# store event times\n",
    "E = session.recordnodes[0].recordings[0].events\n",
    "\n",
    "# get absolute start time of the ephys data \n",
    "oe_start_text = ET.parse(os.path.join(oe_dir,'settings.xml')).getroot().find('./INFO/DATE').text\n",
    "oe_start = datetime.strptime(oe_start_text,'%d %b %Y %H:%M:%S')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6743fecb-7dbf-4843-8e1b-31c3f85e4026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get camera exposure times\n",
    "\n",
    "\n",
    "# get timestamps\n",
    "cam_starts = np.array(E.timestamp[(E['line'] == 4) & (E['state'] == 1)])\n",
    "cam_ends = np.array(E.timestamp[(E['line'] == 4) & (E['state'] == 0)])\n",
    "\n",
    "# if session starts with camera off (falling below threshold), delete first camera end time\n",
    "if cam_ends[0] < cam_starts[0]:\n",
    "    cam_ends = cam_ends[1:]\n",
    "\n",
    "# compute differentials\n",
    "cam_start_deltas = np.diff(cam_starts)\n",
    "cam_lengths = np.array([e-s for (e,s) in zip(cam_ends,cam_starts)])\n",
    "\n",
    "\n",
    "# identify bursts\n",
    "\n",
    "# identify first and last index from each burst\n",
    "big_deltas = np.where( cam_start_deltas > inter_burst_interval )[0]\n",
    "new_burst_start_inds = np.concatenate(([0],big_deltas+1))\n",
    "new_burst_end_inds = np.concatenate((big_deltas,[len(cam_starts)-1]))-1\n",
    "\n",
    "# sort into image starts and image stops for each burst\n",
    "for ii in range(len(new_burst_start_inds)):\n",
    "    start_ind = new_burst_start_inds[ii]\n",
    "    end_ind = new_burst_end_inds[ii]\n",
    "    burst_times = cam_starts[start_ind:end_ind+1]\n",
    "    #print(len(burst_times))\n",
    "\n",
    "\n",
    "\n",
    "n_bursts = len(new_burst_start_inds)\n",
    "\n",
    "# identify long bursts, ie those likely to have been saved as image series\n",
    "burst_durations = [e-s for s,e in zip(cam_starts[new_burst_start_inds],cam_starts[new_burst_end_inds])]\n",
    "min_burst_duration = np.median(burst_durations)/2\n",
    "long_bursts = np.where(burst_durations>min_burst_duration)[0]\n",
    "\n",
    "\n",
    "print(f\"Recording start: {oe_start}\")\n",
    "print(f\"   Events begin: {oe_start + timedelta(seconds=E.timestamp.iloc[0])}\")\n",
    "print(f\"     Events end: {oe_start + timedelta(seconds=E.timestamp.iloc[-1])}\")\n",
    "print(\"\")\n",
    "print(f\"Camera starts: {len(cam_starts):,}\")\n",
    "print(f\"  Camera ends: {len(cam_ends):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c69f3c-b646-4b4b-8092-ec4ff84fec20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the correct bpod mat file using # trials\n",
    "\n",
    "# Load bpod triggers from OE file\n",
    "bpod_channel = event_channel_names.index('bpod lick trials') + 1\n",
    "bpod_starts = np.array(E.timestamp[(E['line'] == bpod_channel) & (E['state'] == 1)])\n",
    "bpod_ends = np.array(E.timestamp[(E['line'] == bpod_channel) & (E['state'] == 0)])\n",
    "\n",
    "# Show bpod event count from OE file\n",
    "print(f\"{len(bpod_starts):,} bpod starts\")\n",
    "print(f\"{len(bpod_ends):,} bpod ends\")\n",
    "print(\"\")\n",
    "\n",
    "# Show trial count from each bpod file\n",
    "bpod_files = sorted(glob.glob(os.path.join(bpod_dir, '*.mat')))\n",
    "\n",
    "if len(bpod_files) == 0:\n",
    "    print(\"No .mat files found in bpod_dir!\")\n",
    "    print(f\"bpod_dir: {bpod_dir}\")\n",
    "    print(f\"Directory exists: {os.path.exists(bpod_dir)}\")\n",
    "else:\n",
    "    for bb, file_name in enumerate(bpod_files):\n",
    "        try:\n",
    "            behavior_info = helper.load_one_behavior_info(file_name)\n",
    "            n_trials = behavior_info['n_trials']\n",
    "            print(f\"{n_trials} trials in file {bb}\")\n",
    "            print(f'     {file_name}')\n",
    "            \n",
    "            # Check for mismatch\n",
    "            if n_trials != len(bpod_starts):\n",
    "                print(f\"     ⚠️  MISMATCH: {n_trials} trials in .mat vs {len(bpod_starts)} bpod starts in OE\")\n",
    "            else:\n",
    "                print(f\"     ✅ MATCH: {n_trials} trials matches {len(bpod_starts)} bpod starts\")\n",
    "            print()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file {bb}: {e}\")\n",
    "            print(f'     {file_name}\\n')\n",
    "\n",
    "print(f\"Bpod files found: {bpod_files}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780a99d2-3ce1-41a5-89aa-b26b2e5165d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load bpod file\n",
    "bpod_file = bpod_files[0]\n",
    "bpod_session = sio.loadmat(bpod_file)[\"SessionData\"]\n",
    "behav_info = helper.load_one_behavior_info(bpod_file)\n",
    "\n",
    "# convert bpod mat file events to OE times\n",
    "bpod_events = helper.convert_bpod_mat_to_oe(bpod_session, bpod_starts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864c005a-f056-4405-9056-94727d473a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load basic info for each image series (including first index)\n",
    "\n",
    "# For each image series:\n",
    "#\n",
    "#  - identify files\n",
    "#  - store file names\n",
    "#  - load exposure index of first image (if saved)\n",
    "\n",
    "# Check if we have series### directories or just session_1\n",
    "regex = re.compile(r\"series\\d{3}$\")\n",
    "series_folders = [f for f in Path(flex_dir).iterdir() if f.is_dir() and regex.match(f.name)]\n",
    "\n",
    "# If no series directories found, check for session_1 structure\n",
    "if len(series_folders) == 0:\n",
    "    session_dir = Path(flex_dir) / \"session_1\"\n",
    "    if session_dir.exists():\n",
    "        print(\"No series### directories found, using session_1 structure\")\n",
    "        # Treat the main flex_dir as series000\n",
    "        series_folders = [Path(flex_dir)]\n",
    "    else:\n",
    "        raise ValueError(f\"No series directories or session_1 found in {flex_dir}\")\n",
    "\n",
    "print(f\"Found {len(series_folders)} series/session directories\")\n",
    "\n",
    "for ss in range(len(series_folders)):\n",
    "    \n",
    "    print('\\033[1m' + 'Series folder: ' + '\\033[0m' + f\"{series_folders[ss]}\")\n",
    "\n",
    "    # find metadata file\n",
    "    if 1:\n",
    "        # make list of possible metadata file names\n",
    "        tiff_metadata_paths = [os.path.join(series_folders[ss],'frame_timestamps.csv'),\n",
    "                              os.path.join(series_folders[ss],'other_possible_name.txt')]\n",
    "        \n",
    "        # search for which exists, if any\n",
    "        tiff_metadata_path = []\n",
    "        for tmp in tiff_metadata_paths:\n",
    "            if os.path.exists(tmp):\n",
    "                tiff_metadata_path = tmp\n",
    "    \n",
    "        # error if none found\n",
    "        if len(tiff_metadata_path) == 0:\n",
    "            print(f\"Warning: No metadata found for {series_folders[ss]}\")\n",
    "            tiff_metadata_path = \"\"\n",
    "        else:\n",
    "            print('\\033[1m' + '     Metadata:\\n' + '\\033[0m'+f\"          {tiff_metadata_path}\")\n",
    "    else:\n",
    "        tiff_metadata_path = ''\n",
    "        print('\\033[1m' + '     No metadata loaded\\n' + '\\033[0m')\n",
    "    \n",
    "    # Search for tif files\n",
    "    # get folder\n",
    "    tiff_folder = os.path.join(series_folders[ss],'session_1')\n",
    "    \n",
    "    if not os.path.exists(tiff_folder):\n",
    "        raise ValueError(f\"Could not find tiff folder {tiff_folder}\")\n",
    "    else:\n",
    "        # get list of files ending in '.tif'\n",
    "        tiff_files_maybe = list(Path(tiff_folder).glob(\"session*.tif\"))\n",
    "\n",
    "        # error if none found\n",
    "        if len(tiff_files_maybe) == 0:\n",
    "            raise ValueError(f\"No .tif files found in {tiff_folder}\")\n",
    "\n",
    "        # convert to strings\n",
    "        tiff_files_maybe = [str(f) for f in tiff_files_maybe]\n",
    "\n",
    "        # sort file names\n",
    "        tiff_files_maybe = sorted(tiff_files_maybe, key=helper.natural_key)\n",
    "    \n",
    "    print('\\033[1m' + f\"     Tif files ({len(tiff_files_maybe)}):\" + '\\033[0m')\n",
    "    for t in tiff_files_maybe[:3]:  # Show first 3 files\n",
    "        print(f\"          {t}\")\n",
    "    if len(tiff_files_maybe) > 3:\n",
    "        print(f\"          ... and {len(tiff_files_maybe)-3} more files\")\n",
    "\n",
    "    # load exposure index of first image (if file exists)\n",
    "    first_index_filename = os.path.join(series_folders[ss],\"first_index.txt\")\n",
    "    \n",
    "    if Path(first_index_filename).is_file():\n",
    "        with open(first_index_filename, \"r\") as file:\n",
    "           first_image_exposure_index = int(file.read())\n",
    "        print('\\033[1m' + \"     First index: \" + '\\033[0m' + f'{first_image_exposure_index}')\n",
    "    else:\n",
    "        first_image_exposure_index = []\n",
    "        print('\\033[1m' + \"     First index: \" + '\\033[0m' + \"not found\")\n",
    "    \n",
    "    print('')\n",
    "    \n",
    "    this_dict = {\"series_path\":series_folders[ss],\n",
    "                 \"tiff_dir\":tiff_folder,\n",
    "                 \"tiff_metadata_path\":tiff_metadata_path,\n",
    "                 \"tiff_files\":tiff_files_maybe,\n",
    "                 \"first_index\":first_image_exposure_index}\n",
    "\n",
    "    if ss==0:\n",
    "        series_dicts = [this_dict]\n",
    "    else:\n",
    "        series_dicts.append(this_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2589b0c-0acf-4cae-a4a8-9c88ed86e3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display info from the OE file and first index (guess?)\n",
    "\n",
    "\n",
    "# Date and time\n",
    "\n",
    "print('\\033[1m' + oe_dir + '\\n' + '\\033[0m')\n",
    "\n",
    "print('\\033[1m' + f\"{'Date':<13}\" + '\\033[0m' + oe_start.strftime('%a, %b %d, %Y'))\n",
    "print('\\033[1m' + f\"{'Start time':<13}\" + '\\033[0m' + oe_start.strftime('%H:%M:%S.%f'))\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "# Event counts per channel\n",
    "\n",
    "print('\\033[1m' + f\"{'Event count':>11}   {'Channel':<9} Data\" + '\\033[0m')\n",
    "print('')\n",
    "\n",
    "for cc in range(8):\n",
    "    #print(cc)\n",
    "    #print(\"     Location: {0:20} Revision {1}\".format(event_channel_names[cc], {cc}))\n",
    "\n",
    "    print(f\"{E.timestamp[E['line'] == cc+1].shape[0]:>11,}   {cc:>4}      {event_channel_names[cc]:<20}\")\n",
    "\n",
    "\n",
    "# Camera exposures\n",
    "\n",
    "print('\\n')\n",
    "print('\\033[1m' + 'Bursts of camera exposures\\n' + '\\033[0m')\n",
    "\n",
    "print('\\033[1m' + f\"{'Burst':<7}{'Event count':>11}{'Duration':>12}{'Hz':>12}{'T_start':>12}{'T_end':>10}\"\n",
    "      f\"{'Index_start':>15}{'Index_end':>13}{'Series':>11}\" + '\\033[0m')\n",
    "print('')\n",
    "\n",
    "\n",
    "for bb in range(n_bursts):\n",
    "    start_time = cam_starts[new_burst_start_inds[bb]]\n",
    "    end_time = cam_starts[new_burst_end_inds[bb]]\n",
    "    n_triggers = new_burst_end_inds[bb] - new_burst_start_inds[bb] + 1\n",
    "    hz = n_triggers/(end_time-start_time)\n",
    "\n",
    "    # guess which image series this might correspond to\n",
    "    which_series_guess = np.where(bb==long_bursts)[0]\n",
    "    if len(which_series_guess)==0:\n",
    "        # if this \n",
    "        which_series_guess = '   '\n",
    "    else:\n",
    "        which_series_guess = f\"guess: {which_series_guess[0]}, \"\n",
    "\n",
    "    # check if file noting series first index exists\n",
    "    which_series_disk = 'no first_index file'\n",
    "    if 'series_dicts' in locals():\n",
    "        this_start = new_burst_start_inds[bb]\n",
    "        for series_idx in range(len(series_dicts)):\n",
    "            # Check if first_index exists and is not empty\n",
    "            first_idx = series_dicts[series_idx][\"first_index\"]\n",
    "            if first_idx and this_start == first_idx:\n",
    "                which_series_disk = f'first_index.txt: {series_idx}'\n",
    "                break\n",
    "\n",
    "    print(f\"{bb:>4}   {n_triggers:>11,}{end_time-start_time:>12.4f}{hz:>12.4f}{start_time:>12.2f}{end_time:>10.2f}\"\n",
    "          f\"{new_burst_start_inds[bb]:>15}{new_burst_end_inds[bb]:>13}{which_series_guess:>13}{which_series_disk}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43623563-98b8-45cf-9660-8a94976908c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create files noting the correspondence between camera bursts and image series folders\n",
    "\n",
    "#raise Exception('Are you sure you want to create these files?????')\n",
    "\n",
    "# Make text files noting the first index of each image series\n",
    "# Note: With session_1 structure, we only have one main directory, so we'll create\n",
    "# first_index.txt for the long bursts that correspond to actual imaging series\n",
    "\n",
    "for bb in range(n_bursts):\n",
    "\n",
    "    # display which image series this might correspond to\n",
    "    which_series = np.where(bb==long_bursts)[0]\n",
    "    if len(which_series)==0:\n",
    "        print(f\"Burst {bb}: Short burst, skipping (not an imaging series)\")\n",
    "    else:\n",
    "        # For session_1 structure, we use the main series folder (index 0)\n",
    "        # and create a first_index.txt file there\n",
    "        series_idx = which_series[0]\n",
    "        print(f\"Burst {bb}: Long burst {series_idx}, corresponds to imaging series\")\n",
    "        \n",
    "        # Since we have session_1 structure, use the main directory\n",
    "        file_name = os.path.join(series_folders[0], \"first_index.txt\")\n",
    "        \n",
    "        # Only write the first long burst's index (subsequent long bursts are different series\n",
    "        # but in session_1 structure they're all in the same directory)\n",
    "        if series_idx == 0:  # Only write for the first long burst\n",
    "            with open(file_name, \"w\") as file:\n",
    "                print(f\"Writing to file {file_name}:\")\n",
    "                print(f\"    {new_burst_start_inds[bb]}\")\n",
    "                file.write(f\"{new_burst_start_inds[bb]}\")\n",
    "        else:\n",
    "            print(f\"    Skipping file creation for subsequent long burst (series_idx={series_idx})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4fc9d9-ca02-4378-9588-5f547b234887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incorporate exposure times from ephys data\n",
    "\n",
    "print(f'Series {0}\\n')\n",
    "print(f'Data from metadata file\\n')\n",
    "\n",
    "# Load metadata\n",
    "series_dict = series_dicts[0]\n",
    "image_metadata_info = helper.get_image_metadata_info(series_dict[\"tiff_files\"],series_dict[\"tiff_metadata_path\"])\n",
    "\n",
    "#print('\\nKeys for image_metadata_info object:')\n",
    "#print(image_metadata_info.keys())\n",
    "\n",
    "# get image exposure times\n",
    "\n",
    "first_index = series_dict[\"first_index\"]\n",
    "\n",
    "the_burst_to_load = np.where(new_burst_start_inds==first_index)[0]\n",
    "\n",
    "if the_burst_to_load.size == 0:\n",
    "    raise Exception(f'Index {first_index} is not the beginning of any burst.')\n",
    "else:\n",
    "    the_burst_to_load = the_burst_to_load[0]\n",
    "\n",
    "exposure_times = cam_starts[new_burst_start_inds[the_burst_to_load]:new_burst_end_inds[the_burst_to_load]+1]\n",
    "\n",
    "print(f\"\\nLoaded {len(exposure_times):,} exposure times from OE file, burst {the_burst_to_load}\")\n",
    "#print(f\"Loaded {len(exposure_times)} exposure times\")\n",
    "\n",
    "# get image count from metadata file\n",
    "image_count = len(image_metadata_info['fs_norm'])\n",
    "\n",
    "# error mismatch between 1) OE file exposures and 2) metadata image count\n",
    "if len(exposure_times) != image_count:\n",
    "    raise Exception(f'Image count ({image_count}) does not match the number of exposures in burst {the_burst_to_load} ({len(exposure_times)})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f5adcf-93cc-4e27-954f-73604962ce75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image data\n",
    "\n",
    "series_path = series_dicts[0]['series_path']\n",
    "\n",
    "\n",
    "\n",
    "im_se = ImageSeries(os.path.join(series_path,'session_1'),\n",
    "                    os.path.join(series_path,'frame_timestamps.csv'),\n",
    "                    n_channels=2)\n",
    "\n",
    "\n",
    "#os.system(\"say done!\")\n",
    "\n",
    "pmi.images.append(im_se)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
